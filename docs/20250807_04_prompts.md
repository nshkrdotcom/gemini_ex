### **Prompt 1 of 4: Foundational Integration - The Data Contract**

**Objective:** This first stage is the most critical. You will integrate the `ALTAR` Data Model (`ADM`) into the `gemini_ex` library. This involves making `gemini_ex` "bilingual"â€”able to speak both its own internal types and the universal `ADM` contract, and correctly serialize `ADM` structs into the precise JSON the Gemini API expects.

**Required Reading:**

1.  **ALTAR (`./ALTER/`)**:
    *   `README.md`: Understand the core principles of `ADM` as the "universal contract."
    *   `lib/altar/adm/`: Review all files. Pay close attention to the struct definitions, typespecs, and the validation logic inside the `new/1` functions of `FunctionDeclaration.ex` and `ToolConfig.ex`.
2.  **Gemini (`./`)**:
    *   `gemini/types/request/generate_content_request.ex`: Understand how a request payload is currently defined.
    *   `gemini/apis/coordinator.ex`: Specifically the `build_generate_request` function. This is where you will inject the new serialization logic.

**Agent Directive:**

1.  **Add Dependency:** Add `{:altar, path: "./ALTER"}` to the `deps` function in `mix.exs`.
2.  **Create a Serialization Module:** Create a new file at `gemini/types/tool_serialization.ex`.
    *   This module, `Gemini.Types.ToolSerialization`, will be responsible for converting `Altar.ADM` structs into plain Elixir maps with `camelCase` string keys, ready for JSON encoding.
    *   Implement `to_api_tool_list(declarations :: [Altar.ADM.FunctionDeclaration.t()]) :: [map()]`.
    *   Implement `to_api_tool_config(config :: Altar.ADM.ToolConfig.t()) :: map()`. This must produce a map like `%{functionCallingConfig: %{mode: "ANY", ...}}`.
3.  **Update Request Builder:**
    *   In `gemini/apis/coordinator.ex`, modify the `build_generate_request` function.
    *   It should now accept `:tools` and `:tool_config` in its `opts`.
    *   If these options are present, it must use your new `Gemini.Types.ToolSerialization` module to convert the `ADM` structs into the correct map format before adding them to the final request map.
4.  **No Execution Logic:** Do not add any tool execution logic. The goal of this prompt is exclusively to prepare and send a valid API request containing tool definitions.
5.  **Write Tests:** Create a new test file, `test/gemini/types/tool_serialization_test.exs`, to validate that your serialization functions produce the exact map structure and key casing that the Gemini API expects.

---

### **Prompt 2 of 4: Deserialization and the Manual Loop Foundation**

**Objective:** Now that we can send tool definitions, we must be able to receive and understand the model's response when it asks us to call a function. You will update the response parsing logic and build the foundation for the manual execution loop.

**Required Reading:**

1.  **ALTAR (`./ALTER/`)**:
    *   `lib/altar/adm/function_call.ex`: The data structure you will be deserializing into.
    *   `lib/altar/adm/tool_result.ex`: The data structure you will need to create in the next step.
2.  **Gemini (`./`)**:
    *   `gemini/types/response/generate_content_response.ex`: Specifically the `Candidate` and `PromptFeedback` structs.
    *   `gemini/types/common/part.ex`: This is the most important file. You will be modifying it.
    *   `gemini/apis/generate.ex`: Specifically the `parse_candidate` and `parse_content` helper functions.

**Agent Directive:**

1.  **Update `Part` Struct:** In `gemini/types/common/part.ex`, add a new field: `field(:function_call, Altar.ADM.FunctionCall.t() | nil, default: nil)`.
2.  **Update Response Parser:**
    *   In `gemini/apis/generate.ex`, modify the `parse_content` function (or its helpers).
    *   It must now recognize the `functionCall` key in an API response part.
    *   When it finds a `functionCall`, it must pass the value to `Altar.ADM.FunctionCall.new/1`.
    *   **Crucially, implement error handling:** If `FunctionCall.new/1` returns an error tuple, the entire response parsing should fail, returning an `{:error, %Gemini.Error{...}}` that clearly states the model returned a malformed `FunctionCall`.
3.  **Create Content Serializer for Results:**
    *   Create a new function `Gemini.Types.Content.from_tool_results(results :: [Altar.ADM.ToolResult.t()])`.
    *   This function will take a list of validated `ToolResult` structs and transform them into a single `Content` struct with the role `tool`. The `parts` of this `Content` will be a list of `%{functionResponse: %{name: ..., response: %{content: ...}}}` maps, precisely matching the API spec.
4.  **Write Tests:** In a new test file, `test/gemini/apis/generate_parsing_test.exs`, write tests that:
    *   Parse a mock API response containing a valid `functionCall` and assert that the correct `Altar.ADM.FunctionCall` struct is present in the final `GenerateContentResponse`.
    *   Parse a mock API response with a *malformed* `functionCall` (e.g., missing name) and assert that it correctly returns an `:invalid_response` error.
    *   Test the `Content.from_tool_results/1` function to ensure it produces the exact structure required by the API.

---

### **Prompt 3 of 4: Implementing the LATER Runtime and Manual Loop**

**Objective:** With the data contracts in place, you will now integrate the `LATER` execution engine and expose a high-level API for developers to perform the manual tool-calling loop.

**Required Reading:**

1.  **ALTAR (`./ALTER/`)**:
    *   `README.md`: The section on the `LATER` architecture.
    *   `lib/altar/later/registry.ex`: The GenServer for storing tool implementations.
    *   `lib/altar/later/executor.ex`: The stateless module for executing calls.
2.  **Gemini (`./`)**:
    *   `gemini/application.ex`: You will be adding a supervisor and a named registry process.

**Agent Directive:**

1.  **Supervise the Registry:**
    *   Create a new supervisor at `gemini/supervisor.ex`.
    *   This supervisor, `Gemini.Supervisor`, should start and supervise `Altar.LATER.Registry`, giving it a registered name: `name: Gemini.Tools.Registry`.
    *   Update `gemini/application.ex` to start `Gemini.Supervisor` in the main application's supervision tree.
2.  **Create the `Gemini.Tools` Facade:**
    *   Create a new file at `gemini/tools.ex` for the `Gemini.Tools` module.
    *   This module will be the public API for all tool-related actions.
    *   Implement `Gemini.Tools.register(declaration, fun)`: This function will be a simple wrapper that calls `Altar.LATER.Registry.register_tool(Gemini.Tools.Registry, declaration, fun)`.
    *   Implement `Gemini.Tools.execute_calls(function_calls)`: This function will take a list of `%FunctionCall{}` structs. It will use a `Task.async_stream` to execute them in parallel using `Altar.LATER.Executor.execute_tool(Gemini.Tools.Registry, call)`. It should collect the resulting `ToolResult` structs.
3.  **Formalize Chat History:**
    *   Create a new `Gemini.Chat` module and struct. The struct should contain `history: [Gemini.Types.Content.t()]` and other configs.
    *   Implement `Gemini.Chat.add_turn(chat, content_or_structs)` that correctly appends new `Content` structs (including user prompts, model `function_call`s, and tool `function_response`s) to the history and returns a new chat struct.
4.  **Write Integration Tests:** Create `test/gemini/tools_manual_loop_test.exs`. This test will:
    *   Register a mock tool using `Gemini.Tools.register/2`.
    *   Call `Gemini.generate_content/2` with a prompt designed to trigger the tool.
    *   Assert that the response contains the expected `FunctionCall`.
    *   Pass the call to `Gemini.Tools.execute_calls/1`.
    *   Assert that you receive the correct `ToolResult`.
    *   Use `Content.from_tool_results/1` to create the response content.
    *   Call `Gemini.generate_content/2` a second time with the full history.
    *   Assert that the final response is a text answer that correctly uses the information from the tool's result.

---

### **Prompt 4 of 4: The Automatic Execution Loop**

**Objective:** Implement the "magic loop" that hides the complexity of the multi-turn tool-calling process from the end-user, for both standard and streaming requests.

**Required Reading:**

1.  **Gemini (`./`)**:
    *   `gemini.ex`: You will be adding the new high-level API functions here.
    *   `gemini/streaming/unified_manager.ex`: The GenServer that will need to be modified to handle the complex state of the automatic streaming loop.

**Agent Directive:**

1.  **Implement the Standard Automatic Loop:**
    *   Create a new function `Gemini.generate_with_tools(contents, opts)`.
    *   This function will implement the state machine logic: `call -> check response -> if text, return; if call, execute -> format result -> call again with history -> return final text`.
    *   This logic should be contained within a private helper function, likely with recursion and a turn-limit/timeout to prevent infinite loops.
    *   All tool execution must use the `Gemini.Tools.execute_calls/1` function created in the previous step.
2.  **Modify the `UnifiedManager` for Streaming:** This is the most complex task.
    *   Add a new `handle_call` for a new type of stream, e.g., `{:start_auto_stream, ...}`.
    *   The GenServer's internal state (`stream_state`) must be expanded to track the multi-turn nature of the call (e.g., `status: :awaiting_function_call`, `status: :awaiting_final_response`).
    *   When a `functionCall` is received in a stream event, the manager must *not* forward it to the user. Instead, it should trigger an internal state transition.
    *   It will then call `Gemini.Tools.execute_calls/1`.
    *   After execution, it must construct the `FunctionResponse` and initiate a *new* streaming HTTP request to the Gemini API with the updated history.
    *   It must then proxy the events from this *second* HTTP stream to the original subscriber.
    *   Implement robust error handling for every step (tool execution fails, second stream fails, etc.).
3.  **Write High-Level API Tests:** In `test/gemini_test.exs`, add new tests for `Gemini.generate_with_tools/2`.
    *   Test the full, automatic, end-to-end flow for a standard request.
    *   Test the full, automatic, end-to-end flow for a streaming request, ensuring that the user only receives the final text chunks after the tool has been executed behind the scenes.
